Knowledge Graph Enhanced Language Agents for Recommendation
Taicheng Guo1*, Chaochun Liu2, Hai Wang2, Varun Mannam2, Fang Wang2, Xin Chen2,
Xiangliang Zhang1, Chandan K. Reddy2
1University of Notre Dame2Amazon
{tguo2, xzhang33 }@nd.edu, {chchliu, ihaiwang, mannamvs, fwfang, xcaa, ckreddy }@amazon.com
Abstract
Language agents have recently been used to simulate human
behavior and user-item interactions for recommendation sys-
tems. However, current language agent simulations do not un-
derstand the relationships between users and items, leading to
inaccurate user profiles and ineffective recommendations. In
this work, we explore the utility of Knowledge Graphs (KGs),
which contain extensive and reliable relationships between
users and items, for recommendation. Our key insight is that
the paths in a KG can capture complex relationships between
users and items, eliciting the underlying reasons for user pref-
erences and enriching user profiles. Leveraging this insight,
we propose Knowledge Graph Enhanced Language Agents
(KGLA) , a framework that unifies language agents and KG
for recommendation systems. In the simulated recommenda-
tion scenario, we position the user and item within the KG
and integrate KG paths as natural language descriptions into
the simulation. This allows language agents to interact with
each other and discover sufficient rationale behind their in-
teractions, making the simulation more accurate and aligned
with real-world cases, thus improving recommendation per-
formance. Our experimental results show that KGLA signif-
icantly improves recommendation performance (with a 33%-
95% boost in NDCG@1 among three widely used bench-
marks) compared to the previous best baseline method.
Introduction
Large Language Model (LLM) agents have demonstrated
strong capabilities in conversation and decision-making
across various tasks (Xi et al. 2023; Guo et al. 2024,
2023a). By enabling multiple LLM agents to cooperate, each
agent can have its profile, actions, and behaviors, simulat-
ing diverse human behaviors. Recent works have employed
LLM Agents to simulate real-world recommendation sce-
narios (Zhang et al. 2024b). In these simulations, each agent
represents a user or an item in the recommendation system,
and each agent maintains a memory that records the user
or item’s profiles. The interactions between agents simu-
late user interactions with items, dynamically updating the
agents’ memories to reflect changes in user preferences or
the recognition of unique item features.
While LLM Agents can capture more explainable and ex-
plicit user profiles through text during the recommendation
*Work was done as an intern at Amazon.process, previous work has only considered adding short, ba-
sic descriptions of users and items as prompts during the in-
teractions. As a result, the updated memory for user agents
is nonspecific and general due to a lack of rational informa-
tion about the user’s choice (see Figure 1). With these insuf-
ficient memory profiles, LLMs struggle to identify precise
user preferences and may recommend irrelevant items. In
this work, we analyze the reason for insufficient user agent
and item agent profiles, primarily due to the simulation rely-
ing solely on simple descriptions without rationalizing why
users like or dislike certain items. Consequently, most user
or item agent memories are generated by LLMs based on
limited information. Such profiles heavily rely on the pre-
trained knowledge of LLMs, making them susceptible to
generating generic profiles. User profiling is a critical task
for recommender systems. Hence, addressing the question
of‘how to provide user agents with sufficient information
during Agent simulation to obtain more rational and precise
user profiles?’ remains a crucial but unresolved problem.
To tackle this issue, we aim to leverage a Knowledge
Graph (KG) containing entities with specific meanings to
provide extensive rationales to enhance agent simulation
for recommendation. For example, KG paths can provide
rationales for why a user may like an item (Usermentions−→
featuresdescribe as−→ CD), thus helping to build better user and
item agent profiles. Most of the previous work on using KGs
for recommendation represents the knowledge from a KG in
the form of embeddings and trains a graph neural network
to obtain graph embeddings, which are then concatenated
with user embeddings to represent user profiles. In contrast,
since we use LLM Agents to simulate users and items when
the number of interactions is limited and the user or item
profiles are represented by text, the KG information should
also be represented by text to effectively influence the agent
simulation process.
Based on this motivation, we first identify the informa-
tion from the KG required for recommendation. We for-
mulate this as a ‘ path-to-text ’ problem, where the user and
item can be regarded as nodes in a KG, and paths between
the user and item indicate the rationales for why the user
chooses that item, thus helping to build more precise user
agent memory. There are a few previous works that focus on
leveraging KGs for LLM agents (Jiang et al. 2024; Xu et al.arXiv:2410.19627v1  [cs.AI]  25 Oct 2024
(a) Without KG
 (b) With KG
Figure 1: Examples of user agent memory generated (a) without KG and (b) with KG. The user agent memory generated without
KG only contains some general descriptions, while the memory generated with KG includes more specific terms (highlighted
in red), demonstrating more precise user preferences.
2024; Luo et al. 2023). However, to the best of our knowl-
edge, most previous KG+Agent methods primarily focus on
the question-answering task, where given a question, the
agent starts from a node in the KG and traverses the graph
to find the answer node deductively. Contrary to the previ-
ous works on KG-enhanced LLM agent, in our setting, we
know the start and destination entities (user and item, respec-
tively) in the KG, and we need the LLM agent to analyze
paths between the nodes and summarize the key rationales.
To achieve this, we propose KGLA: Knowledge Graph En-
hanced Autonomous Language Agents , consisting of three
modules: Path Extraction, Path Translation, and Path Incor-
poration to extract, translate, and incorporate KG paths, re-
spectively, for providing faithful rationale information for
improving agent profiles in recommendation. Based on our
proposed framework, we conduct an in-depth analysis of
how our proposed method improves agent simulation for
recommendation, thereby enhancing recommendation per-
formance.
To summarize, our key contributions in this work are:
• To the best of our knowledge, we are the first to lever-
age KGs and demonstrate the effectiveness of KGs in en-
hancing agent profiles for recommendation.
• We identify the challenges and propose a novel frame-
work to extract, translate, and incorporate KG informa-
tion into language agents-based recommendations. The
KG-enhanced framework provides better explanations ofthe recommendation process and is also applicable to var-
ious other KG+Agent simulation tasks.
• We demonstrate the effectiveness of our method through
experiments on various public datasets. The results
show that our method consistently outperforms baselines
(achieving relative improvements of 95.34%, 33.24%,
and 40.79% in NDCG@1 on three widely used bench-
marks, compared to the previous best baseline), and the
agent memories are more precise than previous baselines.
Related Work
LLM Agents
Large language model-based agents are widely researched
for various scenarios. These agents can take actions, interact
with the environment, and obtain feedback. The key capa-
bilities of LLM agents are: 1) Take Action (Yao et al. 2022):
Prompting the agent to perform an action or make a deci-
sion; 2) Reflection (Shinn, Labash, and Gopinath 2023): Af-
ter taking an action, the agent receives feedback from the
environment, which allows it to reflect on the task and im-
prove decision making in subsequent trials; and 3) Mem-
ory (Zhang et al. 2024c): Agents store the lessons learned
from reflection. In our work, during the simulation stage, the
user agent first selects a preferred item from a list of items
(Taking Action). Given the ground-truth item, the agent then
reflects on its previous choice (Reflection). Subsequently, it
updates its profile to record its preference (Memory). In the
ranking stage, the user agent provides a preferred rank list
of items (Taking Action) based on the given list.
LLM Agents for Recommendation
Due to the strong capabilities of LLM agents, they have suc-
cessfully been employed in recommendation tasks. (Wang
et al. 2024) proposes two categories in agent-based recom-
mendation: recommender-oriented and simulation-oriented.
The recommender-oriented approach aims to develop a rec-
ommender agent equipped with enhanced planning, reason-
ing, memory, and tool-using capabilities to assist in rec-
ommending items to users. RecMind (Wang et al. 2023b)
and InteRecAgent (Huang et al. 2023) both develop sin-
gle agents with improved capabilities for recommendation.
RAH (Shu et al. 2023) and MACRec (Wang et al. 2024) sup-
port collaboration among different types of agents to recom-
mend items to users.
In contrast, the simulation-oriented approach focuses on
using agents to simulate individual user behaviors and
item characteristics. RecAgent (Wang et al. 2023a) and
Agent4Rec (Zhang et al. 2024a) employ agents as user sim-
ulators to simulate interactions between users and recom-
mender systems, investigating the plausibility of simulated
user behaviors. AgentCF (Zhang et al. 2024b) explores sim-
ulating user-item interactions using user agents and item
agents. The memories of user agents and item agents are dy-
namically updated during the simulation, and the final mem-
ory is used to recommend items to users.
Our work falls under the category of simulation-oriented
approaches. Previous simulation work only focused on us-
ing agent memory to simulate user profiles for the recom-
mendation, neglecting the construction of high-quality user
agent memories. Poor user agent memory can impair rec-
ommendation performance. Our work leverages KGs to in-
corporate comprehensive rationale information into the en-
tire process of LLM Agents-based recommendation , thereby
building well-grounded and precise user agent memories.
Knowledge Graph and LLM Agents
With the latest advances in LLMs, they are utilized in syn-
ergy with KGs to provide accurate information. Most previ-
ous works (Jiang et al. 2024; Xu et al. 2024; Luo et al. 2023)
focus on synergizing LLM and KGs for question-answering
tasks. The synergizing paradigm is deductive - Given a ques-
tion, LLMs identify the starting entity node and then act
as planners to generate relation paths, traversing the KG to
reach potential entities that can answer the question. How-
ever, the synergizing paradigm between LLMs and KGs in
recommendation systems is inductive and differs from previ-
ous methods. In this context, the starting entity node (user)
and the target entity node (item) are already known within
the KG. LLMs are responsible for analyzing all the paths
between these two nodes and summarizing the key reasons
why the user node can reach the target node. These ratio-
nales are then used to update the user agent’s memory. In
contrast to previous work, our approach is the first to lever-
age LLM agents to inductively analyze KG paths for reflec-
tion, thereby enhancing recommendation performance.Methodology
Notation and Problem Definition
We will first introduce the required notations and define the
problem.
Recommender System. Let the user set be denoted by U,
and the item set be denoted by I. Each user u∈Uhas an
interaction history [i1, i2, . . . , i n]. We have a ground-truth
label yindicating whether the user likes an item ( y= 1) or
does not like it ( y= 0).
Knowledge Graph. A KG is a structured representation
of knowledge that contains abundant facts in the form of
triples G={(eh, r, et)|eh, et∈ E, r∈ R} , where eh
andetare head and tail entities, respectively, and ris the re-
lation between them. Eis the entities set in the KG and Ris
the relations set in the KG. A path in a KG is a sequence of
triples: p=e0r1− →e1r2− →. . .rl− →el, connecting the entity
e0to the entity el.
LLM Agent and LLM Recommendation. For the LLM
agent, we denote its memory as M. During the simulation
stage, the reflection process for the agent is represented by
the function Reflection . In the ranking stage, given a user
and a list of items, the LLM used to generate the ranked list
is represented by the function LLM .
Overall Framework
The architecture of our proposed framework (see Figure 2
and Algorithm 1) has three stages: Initialization ,Simula-
tion andRanking . It is designed to combine LLM agents
with KGs to enhance agent memory during simulation and
improve recommendation performance during ranking. In
theinitialization stage , the memories of all users are set us-
ing the template “I enjoy ...,” while item memories are ini-
tialized with the titles and categories of the items.
Thesimulation stage consists of two phases: Autonomous
Interaction and Reflection. Given a user uwith a chrono-
logical sequence of behavioral interactions [i1, i2, . . . , i n],
the simulation stage aims to optimize the memories repre-
senting the user and item profiles by simulating real-world
user-item interactions. At the beginning of the simulation,
we initialize the user and item agent memories MuandMi,
using basic properties. Then similar to most sequential rec-
ommendation settings (Wang et al. 2019; Guo et al. 2023b),
for each user u, we use items [i1, i2, . . . , i n−1], except the
last item inof the behavior sequences, as positive items for
simulation. At each step of the interactions between uand
ij∈[i1, i2, . . . , i n−1], we randomly sample a negative item
i−with high popularity among all items Ito help the user
agent refine their profiles better through comparison. We use
the last item inas the ground-truth item in the ranking stage
for testing.
For each user uand item i, we first position these nodes in
the KG. Then, we use our Path Extraction module to extract
all 2-hop paths Pui
2=u→e1→iand 3-hop paths Pui
3=
u→e1→e2→ifrom the KG. Based on the extracted
paths, we apply our Path Translator module to convert Pui
2
to text Tui
2andPui
3to text Tui
3. Finally, we apply our Path
Figure 2: The framework of our proposed KG-enhanced Agent Simulation for recommendation. Given (u, i+, i−), our frame-
work can retrieve and translate KG information which would be incorporated into the Simulation, guiding LLM agents to
analyze the possible reasons for user choices based on KG, summarize the user’s precise preferences, and update the user
agent’s memory.
Incorporation module to incorporate Tui
2andTui
3into the
LLM Agents’ simulation and ranking process.
In the Autonomous Interaction phase, we ask the user
agent to choose an item from i+andi−based on the current
user and item memories Mu,Mi, and Mi−, as well as the
2-hop relations between the user and items Tui
2andTui−
2.
After each interaction, the user agent selects an item iselect
and we also ask the user agent to provide explanations yexp
for this choice. To optimize the user agent and item agents,
we derive the feedback signal by comparing the user agent’s
chosen item with the actual interacted item. In the Reflec-
tion phase, we inform the user agent whether the previous
choice was correct or incorrect. Simultaneously, we incorpo-
rate the knowledge graph information Tui
2andTui
3to enable
the user agents to analyze the reasons behind their choices
abductively and summarize key factors to update their mem-
ory. We also update the memory of item agents based on the
information from KG paths.
In the ranking stage , we have user and item agents repre-
senting real-world user and item profiles. We focus on rank-
ing the candidate items given a user uand a set of candidates
{c1, ..., c n}, the user agent’s memory Mu, the memories of
all candidates {Mc1, ..., M cn}, and 2-hop KG information
for each candidates. Ris the final ranking list. In the follow-
ing sections, we will describe our detailed design to incorpo-
rate KG information with LLM agents for recommendation.
Knowledge Graph Path Extraction
This module aims to extract useful information from the
knowledge graph Gfor building better user and item pro-
files. In recommendation systems, given a user uand his
interaction history, the critical information needed is the ra-tionale behind why uchooses or ignores item i. These ratio-
nales can provide detailed preference information that helps
the user agent build a more accurate and comprehensive pro-
file. In G, paths between two nodes can explain why one
node has a relation to another node, which can actually help
explain why the user node uchooses or does not choose the
item node iinG. Hence, our first task is to extract paths
as additional contexts for the following prompt. To achieve
this, we propose the following path extraction procedure: for
each user uand item i, we first extract the 2-hop knowledge
path set Pui
2and 3-hop path set Pui
3, where P2contains all
2-hop paths and P3contains all 3-hop paths from utoi.
Path Translation: Expressing 2-hop Paths via Text
All 2-hop and 3-hop paths extracted from KG are repre-
sented as triples or quaternions. Since the input to LLM is in
text format, our objective is to express these 2-hop and 3-hop
paths in a textual form that LLM can understand. We iden-
tify two critical challenges in this translation process: De-
scription Simplification and easily comprehensible to LLM.
Description Simplification refers to the need to simplify
the textual representation of the extracted paths, as the num-
ber of 2-hop and 3-hop paths can be large. If we do not
shorten the text, its length may exceed the token limit of
the LLM. Furthermore, LLMs may struggle to capture im-
portant factors from longer contexts (Liu et al. 2024). Eas-
ily comprehensible to LLM refers to the need for presenting
the path information in a way that the LLM can easily com-
prehend. While directly adding all 2-hop path triples to the
prompt is one approach (Shu et al. 2024), this method neces-
sitates introducing the entire KG to LLM, which is feasible
only for very small graphs. Additionally, LLMs often strug-
Algorithm 1: KG-enhanced Recommendation
Require: Knowledge Graph G, user u, training samples for
u:
{(u, i+
1, i−
1), . . . , (u, i+
n, i−
n)}
where i+is a positive item and i−is a negative item
sampled during autonomous interaction. Testing sam-
ples for u:
{c1, . . . , c n}
Functions EXP-2HOP andEXP-3HOP which express
2-hop and 3-hop paths between uandifor recommen-
dation.
Ensure: Recommend rank list Rto user u.
1:Stage 1: Initialization
2:Initialize user memory Muand item memory Mifor
each item.
3:Stage 2: Simulation
4:foreach(i+
k, i−
k)in training samples do
5: Tui+
2, Tui+
3←EXP-2HOP (G, u, i+),EXP-3HOP
(G, u, i+,{(u, i+
1, i−
1), . . . , (u, i+
n, i−
n)})
6: Tui−
2, Tui−
3←EXP-2HOP (G, u, i−),EXP-3HOP
(G, u, i−,{(u, i+
1, i−
1), . . . , (u, i+
n, i−
n)})
7: // Autonomous Interaction
8: iselect, yexp←fLLM(Mu, Mi+, Mi−, Tui+
2, Tui−
2)
9: // Reflection
10: Mu←Reflection (iselect, yexp, Mi+, Mi−,
Tui+
2, Tui−
2, Tui+
3, Tui−
3)
11: M+
i, M−
i←Reflection (iselect, yexp, Mi+,
Mi−, Tui+
2, Tui−
2, Tui+
3, Tui−
3)
12:end for
13:Stage 3: Ranking
14:{Tc1
2, . . . , Tcn
2} ← { EXP-2HOP (u, c 1), . . . ,
EXP-2HOP (u, cn)}
15:R←fLLM(Mu,{Mc1, . . . , M cn},{Tc1
2, . . . , Tcn
2})
16:Recommend rank list Rto user u.
gle to effectively process and analyze these direct triples.
In recommendation scenarios, we require the LLM to act
as an analyzer, examining the potential critical reasons be-
hind user choices based on the relationships between users
and items. Thus, we aim to translate the triples into more
natural, human-like language to improve the LLM agent’s
understanding of their underlying meaning.
Algorithm 2 provides the details of the expression of 2-
hops via text, and some examples of converting 2-hop and
3-hop to text are shown in Figure 2. We first group all paths
for each user-item pair by the overall edge type of the paths.
For each edge type (r1, r2), we have a subset of paths asso-
ciated with it. Since the start entity (user) and the end entity
(item) are the same within each subset, we merge all paths by
concatenating the second entities as a list. This approach re-
duces the number of 2-hop paths while still representing the
relevant information. To make the text better understandable
for the LLM, we describe the merged formulas by emphasiz-
ing the relationships between the user and the item. For ex-
ample, given a merged paths set ur1− →(e1, e2, ..., e n)r2− →iwith edge type r1=mentions, r 2=describe as, we de-
scribe it as “User mentions features e1, e2, ..., e nwhich are
described as this item”. This approach reduces the length
of the 2-hop path information and explicitly prompts the
LLM to perform better reasoning by highlighting the rela-
tionships.
Algorithm 2: EXP-2HOP ( G, u, i )
Require: Knowledge Graph G, user uand item i. Function
FIND-2HOP (G, u, i )which retrieves all 2-hop paths
between uandi
Ensure: TextTui
2containing natural language descriptions
of 2-hop paths between uandi
1:Pui
2←FIND-2HOP (G, u, i )
2:Group paths by relation types (r1, r2)inPui
2to dictio-
naryD[(r1, r2)]where keys are relation pairs and values
are lists of entities
3:foreach(r1, r2)inDdo
4: Formulate sentence: “The user {r1}D[(r1, r2)]
(list of entities), which are {r2}by the item.”
5: Append sentence to Tui
2
6:end for
7:return Tui
2
Path Translation: Expressing 3-hop Paths via Text
Algorithm 3: EXP-3HOP( G, u, i, {(u, i+
1, i−
1), . . . , (u, i+
n, i−
n)})
Require: Knowledge Graph G, user uand item i, train-
ing samples for u:{(u, i+
1, i−
1), . . . , (u, i+
n, i−
n)}, where
i+is a positive item and i−is a negative item
sampled during autonomous interaction. Functions
FIND-3HOP (G, u, i )which retrieves all 3-hop paths
between uandi, andGET-DESC (P)which returns en-
tities except uandiinvolved in path P
Ensure: TextTui
3containing natural language descriptions
of 3-hop paths between uandi
1:Initialize: positive entity set E+← ∅ , negative entity
setE−← ∅, non-informative entity set Su← ∅
2:foreach(i+
k, i−
k)in training samples do
3: E+←E+∪GET-DESC (FIND-3HOP (G, u, i+
k))
4: E−←E−∪GET-DESC (FIND-3HOP (G, u, i−
k))
5:end for
6:Su←E+∩E−▷Identify non-informative common
entities between positive and negative items.
7:Tui
3←GET-DESC (FIND-3HOP (G, u, i ))
8:Remove non-informative entities: Tui
3←Tui
3\Su
9:return Tui
3
Simplifying the description and making it simpler for the
LLM to understand becomes more challenging for 3-hop
paths because the number and relations of 3-hop paths are
much larger compared to 2-hop paths. Unlike emphasizing
the relations of 2-hop paths, the objective of using 3-hop
paths is to incorporate more descriptive information for up-
dating agents’ memories in the Reflection stage.
Algorithm 3 provides the details of expressing 3-hops
through text. The number of 3-hop paths is too large, as
shown in Table 2. In the Autonomous Interaction and Re-
flection phase for the simulation stage, where the user needs
to select one item among the positive and negative items,
the motivation for adding KG information is to incorporate
discriminative factors between these two items for the user
agent. Therefore, we only need the discriminative features
between the user’s positive item pair and the user’s negative
item pair. Hence, we first construct a non-informative entity
setSufor each user u. Specifically, entities that appear in
both positive items and negative items indicate that they do
not provide useful information for distinguishing user pref-
erences, and thus they will be added to this set. Then, for
useruand item i, we extract the 3-hop paths from the KG,
extract the descriptive entities, and filter based on Su. The
descriptive entities are pre-defined. For example, if a KG
contains four types of entities: user U, item I, category C,
and words W, we only select category Cand words Was
descriptive entities. Finally, we obtain the filtered descrip-
tive entities Tui
3which may indicate the user’s potential ra-
tionales for their choice.
Path Incorporation: Incorporating Text
After obtaining 2-hop and 3-hop text descriptions from the
KGG, we need to incorporate these descriptions into the
overall framework. As shown in Algorithm 1, we incorpo-
rate translated 2-hop KG text into the Autonomous Interac-
tion stage (line 8), 2-hop and 3-hop KG text into the Re-
flection stage (lines 10 and 11), and 2-hop KG text into the
Ranking stage (line 14).
Experiments
Experiment Settings
We conducted extensive experiments to address the follow-
ing research questions (RQs):
• RQ1: Does incorporating KG information enhance the
recommendation performance?
• RQ2: How much do different types of KG information
contribute to the overall performance?
• RQ3: How does KG information influence agent memory
(user profiles) in simulation?
• RQ4: How does the enhanced agent’s memory influence
the ranking?
• RQ5: How much does our method reduce the input word
count for the LLM?
Datasets. Following previous works, we conducted our
experiments on three datasets containing KG, including
the CDs, Clothing, and Beauty which comprises product
review data from existing recommendation benchmarking
datasets (McAuley et al. 2015). Original data sets and
Knowledge Graph (KG) information are sourced from (Xian
et al. 2019)1. To reduce the impact of expensive API calls
and facilitate effective simulations, consistent with previous
1https://github.com/orcax/PGPRsettings (Zhang et al. 2024b), we sample dense recommen-
dation subsets, where most users have rated a large portion
of items. Specifically, we sample 100 users along with their
corresponding items from each dataset for experiments. The
dataset statistics are presented in Table 2. The Knowledge
Graph comprises five types of entities:
• User: User in recommender system
• Item: Product to be recommended to users
• Feature: A product feature word from reviews
• Brand: Brand or manufacturer of the product
• Category: Category of the product
and eight kinds of relations:
•Userpurchase− − − − − − → Item
•Usermention− − − − − → Feature
•Itemdescribe as− − − − − − − → Feature
•Itembelong to− − − − − − → Category
•Itemproduced by− − − − − − − − → Brand
•Itemalsobought− − − − − − − → anotherItem
•Itemalsoviewed− − − − − − − → anotherItem
•Itembought together bysame user− − − − − − − − − − − − − − − − − − − → anotherItem
Evaluation metrics. Similar to previous studies, we used
NDCG@K as an evaluation metric for comparing different
methods, where K is set to 1, 5, and 10. We considered the
items excluding the last item of the user behavior sequences
as the training data for the simulation stage in the recom-
mendation, and the last item as the ground-truth item. To
mitigate the randomness of the LLM, each experiment was
repeated three times, and the mean and standard deviation
were reported.
Baselines
We compared the proposed model with the following cate-
gories of baseline methods available in the literature.
Conventional recommendation methods. We included
BPR (Bayesian Personalized Ranking) (Rendle et al. 2012)
which uses matrix factorization to learn the potential repre-
sentations of users and items and performs recommending
based on these representations; Pop (Popularity-based rec-
ommendation) (Ji et al. 2020) which ranks candidates based
on their popularity; and BM25 (Best Matching 25) (Robert-
son and Zaragoza 2009) which ranks candidates based on
their textual similarity to the user’s past interactions.
Deep-learning based recommendation methods. We
used SASRec (Kang and McAuley 2018) which captures the
sequential patterns of the users’ historical interactions utiliz-
ing a transformer-encoder.
MethodCDs Clothing Beauty
NDCG@1 NDCG@5 NDCG@10 NDCG@1 NDCG@5 NDCG@10 NDCG@1 NDCG@5 NDCG@10
Conventional
Rec.BPR 0.083 ±0.021 0.278 ±0.019 0.441 ±0.018 0.110 ±0.035 0.307 ±0.021 0.462 ±0.020 0.113 ±0.031 0.313 ±0.032 0.468 ±0.021
Pop 0.140 ±0.000 0.346 ±0.000 0.493 ±0.000 0.050 ±0.000 0.227 ±0.000 0.407 ±0.000 0.170 ±0.000 0.359 ±0.000 0.500 ±0.000
BM25 0.050 ±0.000 0.318 ±0.000 0.451 ±0.000 0.130 ±0.000 0.333 ±0.000 0.476 ±0.000 0.180 ±0.000 0.379 ±0.000 0.523 ±0.000
Deep-learning Rec. SASRec 0.163 ±0.025 0.346 ±0.019 0.496 ±0.010 0.157 ±0.015 0.309 ±0.014 0.481 ±0.009 0.153 ±0.012 0.352 ±0.010 0.486 ±0.006
LLM-based
Rec.LLMRank 0.170 ±0.026 0.384 ±0.016 0.515±0.012 0.340±0.026 0.648±0.016 0.676±0.014 0.270±0.010 0.578 ±0.004 0.624±0.005
AgentCF 0.193 ±0.006 0.362±0.012 0.510 ±0.006 0.313 ±0.023 0.528 ±0.020 0.617 ±0.013 0.277 ±0.032 0.539±0.008 0.607 ±0.017
KGLA (Ours) 0.377±0.006 0.637 ±0.009 0.675 ±0.005 0.453 ±0.021 0.699 ±0.016 0.732 ±0.010 0.390 ±0.010 0.655 ±0.003 0.691 ±0.003
Improvement over best baseline: 95.34% 65.89% 31.07% 33.24% 7.87% 8.28% 40.79% 13.32% 10.74%
Table 1: The overall performance comparison in terms of NDCG metric. The best result is in bold font, and the second best
result is underlined.
Datasets #Users #Items #Interactions #Avg. 2-hop #Avg. 3-hop
CDs 100 247 506 13.59 349.77
Clothing 100 258 484 15.56 213.87
Beauty 100 252 494 20.36 337.29
Table 2: Statistics of the sampled datasets and the related
KG. #Avg. 2-hop denotes the average number of 2-hop paths
while #Avg. 3-hop denotes the average number of 3-hop
paths.
LLM-based recommendation methods. We used LLM-
Rank (Hou et al. 2024) as a baseline, which leverages
LLMs as a zero-shot ranker to rank candidate items based
on the user’s sequential interaction history. We compared
our method with AgentCF (Zhang et al. 2024b) which also
builds an Agent Simulation framework to obtain agent mem-
ories that are used for recommendation. Compared to their
model, our method adaptively designs strategies to synergize
the Agent with the KG.
Implementation details. We implemented all baseline
methods (Hou et al. 2024) except AgentCF using the open-
source repository available at2. For all Large Language
Model (LLM)-based methods (LLMRank, AgentCF, and
our methods), we employ Claude3-Haiku-20240307 as the
LLM. We set the maximum number of tokens (max tokens)
to 20,000. All other optional parameters are left at their de-
fault values: the temperature is 1, top p is 1, and top k is
250.
RQ1: Does incorporating KG information enhance
the recommendation performance?
The overall performance of the recommendation measured
by NDCG@K is reported in Table 1. From the results, we
have the following observations:
1)Our method significantly outperforms all baselines in
all datasets. Compared to the previous best baseline, our
methods obtained 95.3%, 44.7%, and 40.8% improvements
in NDCG@1 on the three datasets. This shows that in-
corporating the KG information through our methods can
significantly enhance the model’s ability to make accurate
recommendations.
2)The performance of all LLM-based recommendation
methods surpasses that of conventional and deep learn-
ing methods. This indicates that LLMs can improve the
recommendation performance, especially in settings with
2https://github.com/RUCAIBox/LLMRanka small number of training datasets, due to their strong
generalization capability.
RQ2: How much do different types of KG
information contribute to the overall performance?
To further investigate the effect of different types of KG in-
formation on recommendation performance, we conducted
ablation studies on the CD dataset. The results are presented
in Table 3, which show that incorporating 2-hop and 3-hop
information from the KG can gradually improve the perfor-
mance metrics. This demonstrates that each module con-
tributes positively to the model and can complement each
other, enabling the model to achieve better overall perfor-
mance.
Method NDCG@1 NDCG@5 NDCG@10
AgentCF (Baseline) 0.193 ±0.006 0.362 ±0.012 0.510 ±0.006
KGLA (+KG 2-hop) 0.280 ±0.010 0.497 ±0.016 0.588 ±0.008
KGLA (+KG 3-hop) 0.257 ±0.029 0.518 ±0.011 0.596 ±0.012
KGLA
(+KG 2-hop
+ KG 3-hop)0.377±0.006 0.637 ±0.009 0.675 ±0.005
Table 3: The impact of 2-hop/3-hop KG paths information.
RQ3: How does KG information influence agent
memory (user profiles) in simulation?
Our proposed methods aim to ensure that the text is easily
comprehensible for LLMs. In this experiment, to investigate
whether the LLM understands the incorporated text, we con-
ducted a case study to evaluate the impact of the KG infor-
mation on the agent’s memory during the Reflection stage.
To investigate further the main contribution of our method
to the agent’s memory, we will provide a case study of our
method with KG. As shown in Figure 3, during simula-
tion, with positive and negative items, the LLM can effec-
tively conclude the potential preferred 2-hop features includ-
ing “garden”, “sultry”, “chick” related to the user and help
explore the expanded 3-hop features including “sensual” to
enrich the user profiles.
RQ4: How does the enhanced agent’s memory
influence the ranking?
To investigate how the updated agent memory based on KG
information influences the final recommendation, we show
Figure 3: A case study for KG-enhanced simulation: Fea-
tures in bold font such as “sensual”, “sultry” are summa-
rized by the User Agents as the preferred features while
light-colored features such as “pray”, and “fallen” are sum-
marized by User Agents as the non-informative features.
Figure 4: A case study for KG-enhanced ranking: Take two
candidates as examples, candidate 1 shares more common
features with user agent memory, so the user agent can make
a correct choice in the ranking stage for recommendation.
the following case during the recommendation stage. As il-
lustrated in Figure 4, with the precise and extensive user
profiles and 2-hop relations, candidate 1 shares more com-
mon features with user agent memory, thus providing the
user agent with more rationales to rank the candidates.
RQ5: How much does our method reduce the input
word count for the LLM?
A key objective of our proposed methods is to shorten the
description of KG. In this experiment, we compare the word
count of the original paths with the text generated by our
methods for 2-hop and 3-hop paths. As shown in Table 4,
our methods achieve a substantial reduction in word count,
with around 60% for 2-hop paths and 98% for 3-hop paths,
compared to the original descriptions of the path information
across all datasets.
Conclusion
Using language agents for recommendation is a promis-
ing yet challenging task. Previous works on this topic have
primarily focused on utilizing agents to simulate the rec-
ommendation process, often neglecting the rationale be-
hind recommendations, thus have struggled to discover user
preferences for recommendations. In this paper, we pro-
pose KGLA, the first framework that explores the syner-Word Count CDs Clothing Beauty
2-hop Paths# Avg. paths 13.38 15.56 20.36
# Avg. original w. 40.14 46.68 61.08
# Avg. words 15.38 17.56 22.36
Reduction Percentage 61.68% 62.38% 63.39%
3-hop paths# Avg. paths 312.89 213.87 337.29
# Avg. original w. 1564.45 1069.35 1686.45
# Avg. words 62.73 18.23 25.46
Reduction Percentage 95.99% 98.30% 98.49%
Table 4: Reduction in word counts using the proposed
method. ‘# Avg. original w.’ denotes the word count when
the paths are directly put into LLM. ‘# Avg. words’ denotes
the word count after processing by our method.
gistic combination of LLM agents and KG, enabling agents
to act with improved rationale and better align their pref-
erences with actual recommendation. By leveraging exist-
ing datasets, we conducted extensive experiments to demon-
strate how incorporating KG information refines the agent’s
memory with precise rationales, enabling our method to out-
perform other baselines significantly. Furthermore, our KG-
enhanced framework assists agents in reflecting on ground-
ing faithful KG information and provides better explanations
of the recommendation process.
References
Guo, T.; Chen, X.; Wang, Y .; Chang, R.; Pei, S.; Chawla,
N. V .; Wiest, O.; and Zhang, X. 2024. Large language model
based multi-agents: A survey of progress and challenges.
arXiv preprint arXiv:2402.01680 .
Guo, T.; Nan, B.; Liang, Z.; Guo, Z.; Chawla, N.; Wiest,
O.; Zhang, X.; et al. 2023a. What can large language mod-
els do in chemistry? a comprehensive benchmark on eight
tasks. Advances in Neural Information Processing Systems ,
36: 59662–59688.
Guo, T.; Yu, L.; Shihada, B.; and Zhang, X. 2023b. Few-
shot news recommendation via cross-lingual transfer. In
Proceedings of the ACM Web Conference 2023 , 1130–1140.
Hou, Y .; Zhang, J.; Lin, Z.; Lu, H.; Xie, R.; McAuley, J.;
and Zhao, W. X. 2024. Large language models are zero-shot
rankers for recommender systems. In European Conference
on Information Retrieval , 364–381. Springer.
Huang, X.; Lian, J.; Lei, Y .; Yao, J.; Lian, D.; and Xie, X.
2023. Recommender ai agent: Integrating large language
models for interactive recommendations. arXiv preprint
arXiv:2308.16505 .
Ji, Y .; Sun, A.; Zhang, J.; and Li, C. 2020. A re-visit of the
popularity baseline in recommender systems. In Proceed-
ings of the 43rd International ACM SIGIR Conference on
Research and Development in Information Retrieval , 1749–
1752.
Jiang, J.; Zhou, K.; Zhao, W. X.; Song, Y .; Zhu, C.; Zhu, H.;
and Wen, J.-R. 2024. Kg-agent: An efficient autonomous
agent framework for complex reasoning over knowledge
graph. arXiv preprint arXiv:2402.11163 .
Kang, W.-C.; and McAuley, J. 2018. Self-attentive sequen-
tial recommendation. In 2018 IEEE international confer-
ence on data mining (ICDM) , 197–206. IEEE.
Conclusion
Using language agents for recommendation is a promis-
ing yet challenging task. Previous works on this topic have
primarily focused on utilizing agents to simulate the rec-
ommendation process, often neglecting the rationale be-
hind recommendations, thus have struggled to discover user
preferences for recommendations. In this paper, we pro-
pose KGLA, the first framework that explores the syner-Word Count CDs Clothing Beauty
2-hop Paths# Avg. paths 13.38 15.56 20.36
# Avg. original w. 40.14 46.68 61.08
# Avg. words 15.38 17.56 22.36
Reduction Percentage 61.68% 62.38% 63.39%
3-hop paths# Avg. paths 312.89 213.87 337.29
# Avg. original w. 1564.45 1069.35 1686.45
# Avg. words 62.73 18.23 25.46
Reduction Percentage 95.99% 98.30% 98.49%
Table 4: Reduction in word counts using the proposed
method. ‘# Avg. original w.’ denotes the word count when
the paths are directly put into LLM. ‘# Avg. words’ denotes
the word count after processing by our method.
gistic combination of LLM agents and KG, enabling agents
to act with improved rationale and better align their pref-
erences with actual recommendation. By leveraging exist-
ing datasets, we conducted extensive experiments to demon-
strate how incorporating KG information refines the agent’s
memory with precise rationales, enabling our method to out-
perform other baselines significantly. Furthermore, our KG-
enhanced framework assists agents in reflecting on ground-
ing faithful KG information and provides better explanations
of the recommendation process.
References
Guo, T.; Chen, X.; Wang, Y .; Chang, R.; Pei, S.; Chawla,
N. V .; Wiest, O.; and Zhang, X. 2024. Large language model
based multi-agents: A survey of progress and challenges.
arXiv preprint arXiv:2402.01680 .
Guo, T.; Nan, B.; Liang, Z.; Guo, Z.; Chawla, N.; Wiest,
O.; Zhang, X.; et al. 2023a. What can large language mod-
els do in chemistry? a comprehensive benchmark on eight
tasks. Advances in Neural Information Processing Systems ,
36: 59662–59688.
Guo, T.; Yu, L.; Shihada, B.; and Zhang, X. 2023b. Few-
shot news recommendation via cross-lingual transfer. In
Proceedings of the ACM Web Conference 2023 , 1130–1140.
Hou, Y .; Zhang, J.; Lin, Z.; Lu, H.; Xie, R.; McAuley, J.;
and Zhao, W. X. 2024. Large language models are zero-shot
rankers for recommender systems. In European Conference
on Information Retrieval , 364–381. Springer.
Huang, X.; Lian, J.; Lei, Y .; Yao, J.; Lian, D.; and Xie, X.
2023. Recommender ai agent: Integrating large language
models for interactive recommendations. arXiv preprint
arXiv:2308.16505 .
Ji, Y .; Sun, A.; Zhang, J.; and Li, C. 2020. A re-visit of the
popularity baseline in recommender systems. In Proceed-
ings of the 43rd International ACM SIGIR Conference on
Research and Development in Information Retrieval , 1749–
1752.
Jiang, J.; Zhou, K.; Zhao, W. X.; Song, Y .; Zhu, C.; Zhu, H.;
and Wen, J.-R. 2024. Kg-agent: An efficient autonomous
agent framework for complex reasoning over knowledge
graph. arXiv preprint arXiv:2402.11163 .
Kang, W.-C.; and McAuley, J. 2018. Self-attentive sequen-
tial recommendation. In 2018 IEEE international confer-
ence on data mining (ICDM) , 197–206. IEEE.